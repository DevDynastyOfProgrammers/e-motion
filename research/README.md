# Research & Development Lab

–≠—Ç–∞ –ø–∞–ø–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–¥ –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö, –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ **e-motion**.

## –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ
–í –æ—Ç–ª–∏—á–∏–µ –æ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –ø–∞–ø–∫–∏ `ml/`, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥ –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ (Inference), –ø–∞–ø–∫–∞ `research/` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è:
1.  **–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö** (Data Loading, Cleaning, Augmentation).
2.  **–û–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π** (Training Loops, Hyperparameter Tuning).
3.  **–ê–Ω–∞–ª–∏—Ç–∏–∫–∏** (Visualization, Confusion Matrices, F1-Scores).

> **Note:** –ö–æ–¥ –∑–¥–µ—Å—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç "—Ç—è–∂–µ–ª—ã–µ" –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ (`pandas`, `matplotlib`, `plotly`, `scikit-learn`, `albumentations`), –∫–æ—Ç–æ—Ä—ã–µ **–Ω–µ –≤–∫–ª—é—á–µ–Ω—ã** –≤ —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å–±–æ—Ä–∫—É –∏–≥—Ä—ã –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ä–µ—Å—É—Ä—Å–æ–≤.

---

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞

```text
research/
‚îú‚îÄ‚îÄ fer_loader/           # –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º FER-2013
‚îÇ   ‚îî‚îÄ‚îÄ main.py           # –°–∫—Ä–∏–ø—Ç —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞
‚îú‚îÄ‚îÄ state/                # –õ–æ–≥–∏–∫–∞ "Game Director" (–ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å)
‚îÇ   ‚îú‚îÄ‚îÄ data/             # CSV –¥–∞—Ç–∞—Å–µ—Ç—ã (—ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª–∏)
‚îÇ   ‚îú‚îÄ‚îÄ model/            # –°–∫—Ä–∏–ø—Ç—ã –æ–±—É—á–µ–Ω–∏—è (Pandas/Sklearn)
‚îÇ   ‚îî‚îÄ‚îÄ main.py           # –ü–∞–π–ø–ª–∞–π–Ω –æ–±—É—á–µ–Ω–∏—è State Model
‚îú‚îÄ‚îÄ vision/               # –õ–æ–≥–∏–∫–∞ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è (Emotion Recognition)
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py        # –¢—è–∂–µ–ª—ã–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ (Albumentations)
‚îÇ   ‚îú‚îÄ‚îÄ train.py          # –¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è PyTorch (EmotionCNN)
‚îÇ   ‚îî‚îÄ‚îÄ weights/          # –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ (.pth)
‚îî‚îÄ‚îÄ plots/                # –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ HTML-–æ—Ç—á–µ—Ç—ã –∏ –≥—Ä–∞—Ñ–∏–∫–∏
```

---

## –ö–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å (Workflow)

### –ë–ª–æ–∫ 1: Vision (–ö–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ)
–û–±—É—á–µ–Ω–∏–µ CNN –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è 5 –±–∞–∑–æ–≤—ã—Ö —ç–º–æ—Ü–∏–π.

**1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö:**
–°–∫–∞—á–∞–π—Ç–µ –∞—Ä—Ö–∏–≤ `FER-2013.zip` (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å Kaggle) –∏ —Ä–∞—Å–ø–∞–∫—É–π—Ç–µ –µ–≥–æ —Å –ø–æ–º–æ—â—å—é —É—Ç–∏–ª–∏—Ç—ã:
```bash
uv run research/fer_loader/main.py --source "path/to/FER-2013.zip"
```
*–≠—Ç–æ —Ä–∞—Å–ø–∞–∫—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ `research/vision/data` –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç –∏—Ö —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å.*

**2. –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è:**
```bash
uv run research/vision/train.py
```
*   **–†–µ–∑—É–ª—å—Ç–∞—Ç:** –õ—É—á—à–∏–µ –≤–µ—Å–∞ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ `research/vision/weights/best_emotion_model.pth`.
*   **–°–≤—è–∑—å —Å –ü—Ä–æ–¥–æ–º:** –ü–æ–ª—É—á–µ–Ω–Ω—ã–π —Ñ–∞–π–ª `.pth` –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å –≤ `emotion_model.pth` –∏ –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ –≤ –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –∏–ª–∏ —É–∫–∞–∑–∞—Ç—å –ø—É—Ç—å –≤ `settings.py`. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏ –≤ `research` –∏–¥–µ–Ω—Ç–∏—á–Ω–∞ `ml/vision/models.py`.

---

### –ë–ª–æ–∫ 2: State (–õ–æ–≥–∏–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏)
–û–±—É—á–µ–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ k-NN / Centroid Classifier –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏–≥—Ä–æ–≤–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è (Flow, Tension, Relax) –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ–∫—Ç–æ—Ä–∞ —ç–º–æ—Ü–∏–π.

**1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö:**
–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª `emotional_balance_dataset.csv` –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ `research/state/data/`.

**2. –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞:**
```bash
uv run research/state/main.py
```

*   **–ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç:**
    1.  –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –º–µ–∂–¥—É —ç–º–æ—Ü–∏—è–º–∏ –∏ —Å–ª–æ–∂–Ω–æ—Å—Ç—å—é.
    2.  –†–∞—Å—á–µ—Ç —Ü–µ–Ω—Ç—Ä–æ–∏–¥–æ–≤ (–ø—Ä–æ—Ç–æ—Ç–∏–ø–æ–≤) –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è.
    3.  –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤ –≤ –ø–∞–ø–∫–µ `plots/`.
*   **–†–µ–∑—É–ª—å—Ç–∞—Ç:** –§–∞–π–ª `synthetic_reset_prototypes.npy` –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ **–ø–∞–ø–∫—É –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞** (`ml/state/data/models/`).
*   **–°–≤—è–∑—å —Å –ü—Ä–æ–¥–æ–º:** –ò–≥—Ä–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–¥—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π `.npy` —Ñ–∞–π–ª. –õ–æ–≥–∏–∫–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –≤ `ml/state/model/classifier.py` ‚Äî —ç—Ç–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è NumPy-–≤–µ—Ä—Å–∏—è –ª–æ–≥–∏–∫–∏ –∏–∑ `research`.

---

## üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –ú–µ—Ç—Ä–∏–∫–∏

### Vision Model
*   **Dataset:** FER-2013 (Grayscale 48x48).
*   **Augmentations:** Rotate, Flip, Noise, Brightness (via Albumentations).
*   **Accuracy:** ~65-68% (Standard benchmark for this architecture on FER-2013).
*   **–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å:** –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é ImageNet –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏.

### State Model
*   **Method:** Weighted Cosine Similarity + Euclidean Distance.
*   **Accuracy:** ~80%
*   **–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å:** –ò—Å–ø–æ–ª—å–∑—É–µ—Ç "Confidence Boost" ‚Äî –µ—Å–ª–∏ Vision –º–æ–¥–µ–ª—å —É–≤–µ—Ä–µ–Ω–∞ –≤ —ç–º–æ—Ü–∏–∏, State –º–æ–¥–µ–ª—å –±—ã—Å—Ç—Ä–µ–µ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏–≥—Ä—ã.
